---
title: "Customer Churn Prediction Modeling"
format:
  html:
    toc: true
    toc-depth: 2
    number-sections: true
    css: styles.css
editor: visual
---

Customer churn is a critical challenge for subscription-based businesses because acquiring new customers is often more expensive than retaining existing ones. Identifying which customers are at risk of leaving enables proactive retention actions that protect long-term revenue.

This project builds and compares predictive models to identify customers likely to churn. Using behavioral, engagement, and contract-related data, the analysis evaluates model performance, interprets key churn drivers, and translates findings into actionable business recommendations.

By combining statistical modeling with business insight, this work demonstrates how data-driven decision-making can improve customer retention strategies.

## Libraries

```{r}
#| output: false
#| warning: false
library(tidyverse)          
library(skimr)    
library(corrplot)
library(janitor)
library(tidymodels)
library(randomForest)
library(caret)
library(rpart)      
library(rpart.plot)

```

------------------------------------------------------------------------

## Load Data

```{r}
#| output: false
#| warning: false
df <- read_csv('data/synthetic_customer_behavior_and_churn.csv')
```

------------------------------------------------------------------------

### Preview Data

```{r}
head(df)
```

------------------------------------------------------------------------

## Data Exploration

------------------------------------------------------------------------

### Data Overview

#### Column Names

```{r}
colnames(df)
```

#### Distinct Customers

```{r}
n_distinct(df$customer_id)
```

#### Data Structure

```{r}
glimpse(df)
```

#### Missing Values

```{r}
skim(df)
```

------------------------------------------------------------------------

### Focused EDA

As this dataset is synthetically generated, the exploratory analysis is intentionally concise.

#### Target Variable: Churn

```{r}
df %>% 
  count(churn)
```

#### Correlation

```{r}
numeric_df <- df %>% 
  select(where(is.numeric))

cor_matrix <- cor(numeric_df)

corrplot(cor_matrix,
         method = 'color',
         type = 'upper',
         tl.col = 'black',
         tl.cex = 0.5)
```

#### Simple Churn Comparison

```{r}
df %>% 
  group_by(churn) %>% 
  summarise(across(where(is.numeric), mean))
```

------------------------------------------------------------------------

## Data Preparation

------------------------------------------------------------------------

### Clean Data Types

```{r}
df <- df %>%
  mutate(
    churn = factor(churn),
    gender = factor(gender),
    region = factor(region),
    income_level = factor(income_level),
    subscription_type = factor(subscription_type),
    payment_method = factor(payment_method),
    contract_type = factor(contract_type),
    promotional_response = factor(promotional_response),
    discount_used = factor(discount_used),
    usage_frequency = factor(usage_frequency)
  )

```

------------------------------------------------------------------------

### Drop Redundant Variables

-   `customer_id` is an identifier and is removed before modeling.

-   `total_charges` shows a strong correlation with `monthly_charges`. To reduce multicollinearity, `total_charges` is removed before modeling.

-   `signup_date` adds limited value because `tenure_months` captures duration more directly.

```{r}
df <- df %>% 
  select(-customer_id, -total_charges, -signup_date)
```

------------------------------------------------------------------------

### Split Data

Split the data into a training set and a test set.

```{r}
set.seed(1998)

churn_split <- initial_split(df, prop = 0.8, strata = churn)
churn_train <- training(churn_split)
churn_test <- testing(churn_split)
```

Check whether proportions in the training and testing data are similar to the full dataset.

```{r}
count(churn_train, churn) %>% 
  mutate(prop = round(n/sum(n),2))
```

```{r}
count(churn_test, churn) %>% 
  mutate(prop = round(n/sum(n),2))
```

Both sets show similar churn proportions, which supports a representative split for training and evaluation.

------------------------------------------------------------------------

## Modeling

Two models are created and evaluated: logistic regression and a decision tree. Based on their performance, business recommendations are formulated.

------------------------------------------------------------------------

### Logistic Regression

```{r}
model1 <- glm(churn ~ .,
              data   = churn_train,
              family = binomial(link = 'logit'))

pred <- predict(model1 , newdata = churn_test, type = 'response')

# Convert probabilities to classes
pred <- as.factor(ifelse(pred > 0.5, 1, 0))

# Evaluation Metrics
result    <- confusionMatrix(data = pred, churn_test$churn, positive = '1')
precision <- result$byClass['Pos Pred Value']
recall    <- result$byClass['Sensitivity']
F1        <- result$byClass['F1']

```

```{r}
result
```

------------------------------------------------------------------------

### Decision Tree

```{r}
tree_model <- rpart(churn ~ .,
                    data = churn_train,
                    method = "class",
                    control = rpart.control(xval = 10))

# Plot
rpart.plot(tree_model)
```

```{r}
pred      <- predict(tree_model, newdata = churn_test, type = "class")
result    <- confusionMatrix(data = pred, churn_test$churn, positive = '1')
precision <- result$byClass['Pos Pred Value']
recall    <- result$byClass['Sensitivity']
F1        <- result$byClass['F1']
```

```{r}
result
```

------------------------------------------------------------------------

## Business Insights

------------------------------------------------------------------------

### Interpretation of Results

The logistic regression model achieved strong predictive performance with high accuracy and balanced accuracy. It correctly identifies most churners while maintaining strong precision, meaning most customers predicted to churn truly exhibit churn behavior.

Key churn drivers from the logistic regression coefficients:

-   `Satisfaction score` (-1.47, ***p*** **\< .001**)
-   `Number of support tickets` (+0.66, ***p*** **\< .001**)
-   `Last login days ago` (+0.096, ***p*** **\< .001**)
-   `Contract type - yearly` (-1.38, ***p*** **\< .001**)
-   `Tenure` (-0.053, ***p*** **\< .001**)

Demographic variables were largely insignificant, suggesting churn is primarily driven by engagement and behavioral factors rather than personal characteristics.

The decision tree model achieved slightly higher recall, meaning it identifies more potential churners. This comes at the cost of lower precision, resulting in more false positive churn predictions.

Overall trade-off in model choice:

-   **Logistic regression**: More precise, fewer false churn alarms.
-   **Decision tree**: Better at catching potential churners, but with more false positives.

------------------------------------------------------------------------

### Managerial Recommendations

-   Focus retention efforts on behavioral risk signals: low satisfaction, high support tickets, inactivity, short tenure, and monthly contracts. These are the strongest churn drivers.
-   Prioritize improving customer experience and issue resolution, as dissatisfaction and support friction strongly increase churn risk.
-   Encourage yearly subscriptions through incentives, as longer contracts significantly reduce churn probability.
-   Use ***logistic regression*** when retention incentives are costly. Higher precision reduces unnecessary marketing spend by limiting false churn predictions.
-   Use the ***decision tree*** when churn has high financial impact. Higher recall identifies more at-risk customers, even if some incentives are wasted.
-   Consider a tiered retention strategy: strong interventions for high-risk customers and lighter engagement actions for moderate-risk customers to balance budget efficiency and churn prevention.

------------------------------------------------------------------------
